# ETA Pipeline Developer's Guide

This document describes how to add new analytics pipelines to ETA. See
`modules_dev_guide.md` for more information about adding new modules to ETA,
and see `core_dev_guide.md` for instructions on contributing to the core ETA
infrastructure.


## What are ETA Pipelines?

Pipelines are the mechanisms by which analytics capabilities are exposed to the
users of the ETA system. Pipelines define the pre-packaged computations that
users can run on their data, and they expose the relevant inputs, outputs, and
tunable parameters of the analytic that the user can provide, access, and
customize.

Each ETA pipeline is represented internally as a graph whose nodes are ETA
modules and whose edges define the flow of data between the modules. Thus the
ETA pipeline system is general purpose and highly customizable. The ETA
repository defines a collection of pre-configured pipelines that combine the
builtin ETA modules in many ways to useful video analytics capabilities.\

New pipelines can be easily added to the ETA system by writing a simple JSON
configuration file whose syntax is described in the next section.


## Pipeline Metadata JSON Files

Every ETA pipeline must provide a metadata JSON file describing the inputs,
outputs, modules (nodes), and data flow (edges) of the computational graph.

The metadata file contains all the necessary information to instantiate the
pipeline and module configuration files that are required under-the-hood to run
an ETA pipeline on data. The pipeline and associated metadata files of the
constituent modules define a template that is populated by the pipeline builder
for each new piece of input data.

The following JSON gives an example of the metadata file for a simple object
detection pipeline:

```json
{
    "info": {
        "name": "simple-object-detector",
        "version": "0.1.0",
        "description": "A simple object detection pipeline",
        "id": "p1pszsdbmiw4ean4"
    },
    "modules": [
        "resize_videos",
        "sample_videos",
        "detect_objects",
        "visualize_objects"
    ],
    "connections": [
        {
            "source": "INPUT1",
            "sink": "resize_videos.input_path"
        },
        {
            "source": "INPUT1",
            "sink": "visualize_objects.raw_video_path"
        },
        {
            "source": "resize_videos.outpath_path",
            "sink": "sample_videos.input_path"
        },
        {
            "source": "sample_videos.outpath_path",
            "sink": "detect_objects.raw_video_path"
        },
        {
            "source": "detect_objects.objects_json_path",
            "sink": "visualize_objects.objects_json_path"
        },
        {
            "source": "detect_objects.objects_json_path",
            "sink": "OUTPUT1"
        },
        {
            "source": "visualize_objects.visual_vidpath",
            "sink": "OUTPUT2"
        }
    ]
}
```

When discussing pipeline metadata files, we refer to each JSON object `{}` as a
**spec** (specification) because it specifies the semantics of a certain
entity, and we refer to the keys of a JSON object (e.g., "info") as **fields**.

The pipeline metadata file contains the following top-level fields:

- `info`: a spec containing basic information about the module

- `modules`: a list of specs describing the modules (nodes) in the pipeline

- `connections`: a list of specs describing the connections (edges) between
    modules in the pipeline

The `info` spec contains the following fields:

- `name`: the name of the pipeline

- `version`: the current pipeline version

- `description`: a short free-text description of the pipeline purpose and
    implementation

- `id`: the ID of the pipeline, which is a unique identifier generated by the
    ETA maintainers when a new pipeline is registered with the ETA system

The `modules` field contains a list of module (node) specs with the following
fields:

- `label`: a label for the module for use when defining connections

- `module`: a pointer to the module implementation

The `connections` field contains a list of connection (edge) specs with the
following fields:

- `source`: the source (starting point) of the edge. The syntax for a source is
    `"<module_label>.<output_field_name>"`. Alternatively, the special values
    `"INPUT1"`, `"INPUT2"`, etc. can be used to designate a module input as a
    pipeline input

- `sink`: the sink (stopping point) of the edge. The syntax for a sink is
    `"<module_label>.<input_field_name>"`. Alternatively, the special values
    `"OUTPUT1"`, `"OUTPUT2"`, etc. can be used to designate a module output as
    a pipeline output

The pipeline metadata file defines the connectivity of the computation graph.
In practice, the pipeline builder uses this information to instantiate the
necessary configuration files to run a pipeline on new input data.


## Visualizing Pipelines

The ETA system provides the ability to visualize pipelines as block diagrams
using the [blockdiag](https://pypi.python.org/pypi/blockdiag) package.

For example, the block diagram file for the simple object detector described
above can be generated by executing:

```python
from eta.core.pipeline import PipelineMetadata

# Load the pipeline
json_path = "eta/pipelines/simple_object_detector.json"
pipeline_metadata = PipelineMetadata.from_json(json_path)

# Render the block diagram
pipeline_metadata.render("block_diagram.svg")
```

The above code generates a `block_diagram.svg` vector graphics image of the
block diagram. It also generates the following intermediate
`block_diagram.diag` file describing the network architecture:

```
blockdiag {
  // modules
  resize [shape = box];
  sample [shape = box];
  detect [shape = box];
  visualize [shape = box];

  // inputs
  INPUT1 [shape = endpoint];

  // outputs
  OUTPUT1 [shape = endpoint];
  OUTPUT2 [shape = endpoint];

  // parameters
  size [shape = beginpoint];
  fps [shape = beginpoint];
  config_dir [shape = beginpoint];
  model_path [shape = beginpoint];
  weights_path [shape = beginpoint];
  use_gpu [shape = beginpoint];
  labels1 [shape = beginpoint];
  threshold1 [shape = beginpoint];
  show_confidence [shape = beginpoint];
  labels2 [shape = beginpoint];
  threshold2 [shape = beginpoint];
  color [shape = beginpoint];

  // I/O connections
  INPUT1 -> resize;
  INPUT1 -> visualize;
  resize -> sample;
  sample -> detect;
  detect -> visualize;
  detect -> OUTPUT1;
  visualize -> OUTPUT2;

  // parameter connections
  group {
    orientation = portrait;
    size -> resize;
  }
  group {
    orientation = portrait;
    fps -> sample;
  }
  group {
    orientation = portrait;
    config_dir -> detect;
    model_path -> detect;
    weights_path -> detect;
    use_gpu -> detect;
    labels1 -> detect;
    threshold1 -> detect;
  }
  group {
    orientation = portrait;
    show_confidence -> visualize;
    labels2 -> visualize;
    threshold2 -> visualize;
    color -> visualize;
  }
}
```
